{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2526ed4a-35f2-41ec-9af1-97471f6d8720",
   "metadata": {},
   "source": [
    "#### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3a5ff2-56cb-42da-b68b-8db36522a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import stat\n",
    "import requests\n",
    "import urllib.request\n",
    "import glob\n",
    "\n",
    "\n",
    "def download_archive(url, dest):\n",
    "    # download file archive to folder and unpack it into the directory {dest}\n",
    "    print(f\"\\tDownloading raws to ./{dest}/\")\n",
    "    \n",
    "    tmp = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(tmp, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    \n",
    "    shutil.unpack_archive(tmp, dest)\n",
    "    os.remove(tmp)\n",
    "\n",
    "\n",
    "def rmdir(directory):\n",
    "    print(f\"\\tRemoving ./{directory}/\")\n",
    "    # implementing our own version of shutil.rmtree because readonly files throw a permission error when trying to delete them\n",
    "    for root, dirs, files in os.walk(directory, topdown=False):\n",
    "        for name in files:\n",
    "            filename = os.path.join(root, name)\n",
    "            os.chmod(filename, stat.S_IWUSR)  # this is the critical difference between shutil.rmtree(data_dir) and this cell\n",
    "            os.remove(filename)\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n",
    "            \n",
    "    os.rmdir(directory)\n",
    "\n",
    "\n",
    "class BaseDictionary:\n",
    "    top_k = 10\n",
    "    \n",
    "    @classmethod\n",
    "    def get_info(cls, data):\n",
    "        lengths = {k: len(v) for k, v in data.items()}\n",
    "        defns = {k: len(re.findall(\"[\\w-]+\", \" \".join(v))) for k, v in data.items()}\n",
    "        \n",
    "        return {\n",
    "            \"name\": cls.name,\n",
    "            \"source\": cls.url,\n",
    "            \"headwords\": len(data),\n",
    "            \"definitions\": sum(lengths.values()),\n",
    "            \"most_defns\": sorted(lengths.items(), key=lambda x: x[1])[-cls.top_k:],\n",
    "            \"average_words_per_defn\": sum(defns.values()) / len(defns),\n",
    "            \"most_words_in_defn\": sorted(defns.items(), key=lambda x: x[1])[-cls.top_k:],\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def write_to_file(cls, out):\n",
    "        with open(f\"{cls.short_name}.dictionary\", \"w\") as f:\n",
    "            json.dump(out, f, indent=4)\n",
    "            \n",
    "        with open(f\"{cls.short_name}.metadata\", \"w\") as f:\n",
    "            json.dump(cls.get_info(out), f, indent=4)\n",
    "            \n",
    "        print(f'Finished downloading: \"{cls.name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cb979-45b4-4908-b6bc-973facf47775",
   "metadata": {},
   "source": [
    "#### WordNet Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a688014f-1c88-473e-a599-1c084eac9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNet(BaseDictionary):\n",
    "    name = \"WordNet\"\n",
    "    short_name = \"wordnet\"\n",
    "    url = \"http://wordnetcode.princeton.edu/wn3.1.dict.tar.gz\"\n",
    "    \n",
    "    @classmethod\n",
    "    def get_data(cls, data_dir):\n",
    "        print(f\"\\tGetting data from raw\")\n",
    "        raws = f\"./{data_dir}/dict/dbfiles\"\n",
    "    \n",
    "        # scrape all file in the data folder and add to a dictionary of type {word: [defns]}\n",
    "        json_output = {}\n",
    "        for datafile in os.listdir(raws):\n",
    "            word_type = datafile.split('.')[0]\n",
    "                \n",
    "            with open(f\"{raws}/{datafile}\") as f:\n",
    "                raw = f.read()\n",
    "            \n",
    "            for word, defn in re.findall(\"{ \\[\\s*([a-z-]+).+?\\(((?:(?!;).)+).*\\) }\", raw, re.I):\n",
    "                word = word.lower()\n",
    "                if word in json_output:\n",
    "                    json_output[word].append(defn)\n",
    "                else:\n",
    "                    json_output[word] = [defn]\n",
    "\n",
    "        return json_output\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls):\n",
    "        print(f\"Starting download of \\\"{cls.name}\\\"\")\n",
    "        \n",
    "        download_archive(cls.url, \"wordnet_data\")\n",
    "        out = cls.get_data(\"wordnet_data\")\n",
    "        rmdir(\"wordnet_data\")\n",
    "        \n",
    "        # make dict json-serializable\n",
    "        for k, v in out.items():\n",
    "            out[k] = list(v)\n",
    "\n",
    "        cls.write_to_file(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd2b97-82ee-466b-b0f5-ee9934dbc083",
   "metadata": {},
   "source": [
    "#### Online Plain Text English Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9920835b-c94e-40f4-98a6-52d061315ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPTED(BaseDictionary):\n",
    "    name = \"The Online Plain Text English Dictionary\"\n",
    "    short_name = \"opted\"\n",
    "    url = \"https://raw.githubusercontent.com/eddydn/DictionaryDatabase/master/EDMTDictionary.json\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_data(cls):\n",
    "        print(f\"\\tGetting data from raw\")\n",
    "        text = requests.get(cls.url).text\n",
    "        pairs = [(info[\"word\"].lower(), info[\"description\"]) for info in json.loads(text)]\n",
    "        out = {}\n",
    "        for k, v in pairs:\n",
    "            if k not in out:\n",
    "                out[k] = []\n",
    "            out[k].append(v)\n",
    "        return out\n",
    "        \n",
    "    @classmethod\n",
    "    def download(cls):\n",
    "        print(f\"Starting download of \\\"{cls.name}\\\"\")\n",
    "        \n",
    "        out = cls.get_data()\n",
    "        cls.write_to_file(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c402301-d63b-400a-bae7-36d6f34b19c9",
   "metadata": {},
   "source": [
    "#### Websters English Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e7b122-fc64-4d03-b2cf-682e5079fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Webster(BaseDictionary):\n",
    "    name = \"Webster's English Dictionary\"\n",
    "    short_name = \"webster\"\n",
    "    url = \"https://raw.githubusercontent.com/matthewreagan/WebstersEnglishDictionary/master/dictionary_compact.json\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_data(cls):\n",
    "        print(f\"\\tGetting data from raw\")\n",
    "        \n",
    "        text = requests.get(cls.url).text\n",
    "        out = {}\n",
    "        for k, v in json.loads(text).items():\n",
    "            defns = re.split(r\"(?:\\((?:[^\\)\\s]+)\\)|\\d+\\.)\\s*(?=[a-z-]+)\", v, flags=re.I)  # multiple definitions are indicated by \"(a)\", \"(1)\", or \"(Topic.)\"\n",
    "            out[k.lower()] = [a.strip() for a in defns if a]\n",
    "        return out\n",
    "        \n",
    "    @classmethod\n",
    "    def download(cls):\n",
    "        print(f\"Starting download of \\\"{cls.name}\\\"\")\n",
    "        \n",
    "        out = cls.get_data()\n",
    "        cls.write_to_file(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f804839-d506-4588-9cdb-729db5cd7ffb",
   "metadata": {},
   "source": [
    "### Open American National Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e81f04e2-69c8-4668-b493-0c64c5e88fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OANC:\n",
    "    name = \"Open American National Corpus\"\n",
    "    url = \"http://www.anc.org/OANC/OANC_GrAF.zip\"\n",
    "\n",
    "    @staticmethod\n",
    "    def unpack_folder(folder):\n",
    "        parent = '/'.join(folder.split('/')[:-1])\n",
    "        for obj in os.listdir(folder):\n",
    "            shutil.move(f'{folder}/{obj}', parent)\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "        \n",
    "    @classmethod\n",
    "    def download(cls):\n",
    "        print(f\"Starting download of \\\"{cls.name}\\\"\")\n",
    "        main = \"data/OANC\"\n",
    "        download_archive(cls.url, main)\n",
    "        cls.unpack_folder(f\"{main}/OANC-GraF\")\n",
    "        os.remove(f\"{main}/OANC-corpus-header.xml\")\n",
    "        cls.unpack_folder(f\"{main}/data\")\n",
    "        for folder in os.listdir(main):\n",
    "            local = f\"{main}/{folder}\"\n",
    "            os.mkdir(local + \"/out\")\n",
    "            for file in glob.glob(f'{local}/**/*.txt', recursive=True):\n",
    "                shutil.move(file, f'{local}/out/' + file.split('\\\\')[-1])\n",
    "                \n",
    "            for subfolder in os.listdir(local):\n",
    "                if subfolder != \"out\":\n",
    "                    shutil.rmtree(f\"{local}/{subfolder}\")\n",
    "                    \n",
    "            cls.unpack_folder(f\"{local}/out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3042d4-470d-4075-afe2-bf876b6374e6",
   "metadata": {},
   "source": [
    "### War and Peace Raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad1b491-f821-445a-af8f-bc5fda12ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarAndPeace:\n",
    "    name = \"War and Peace\"\n",
    "    url = \"https://www.gutenberg.org/cache/epub/2600/pg2600.txt\"\n",
    "\n",
    "    @classmethod\n",
    "    def download(cls):\n",
    "        print(f\"Starting download of \\\"{cls.name}\\\"\")\n",
    "        urllib.request.urlretrieve(cls.url, \"data/WarAndPeace.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82eb2d9-6438-45d4-ad7b-f849eaac7518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of \"War and Peace\"\n"
     ]
    }
   ],
   "source": [
    "WarAndPeace.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3b090-2b31-463c-a6ad-84030a0c8624",
   "metadata": {},
   "source": [
    "#### Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b536472-4e10-40c5-9c63-4315d27245fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of \"WordNet\"\n",
      "\tDownloading raws to ./wordnet_data/\n",
      "\tGetting data from raw\n",
      "\tRemoving ./wordnet_data/\n",
      "Finished downloading: \"WordNet\"\n",
      "Starting download of \"The Online Plain Text English Dictionary\"\n",
      "\tGetting data from raw\n",
      "Finished downloading: \"The Online Plain Text English Dictionary\"\n",
      "Starting download of \"Webster's English Dictionary\"\n",
      "\tGetting data from raw\n",
      "Finished downloading: \"Webster's English Dictionary\"\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "destination = \"./data\"\n",
    "if not os.path.isdir(destination):\n",
    "    os.mkdir(destination)\n",
    "\n",
    "os.chdir(destination)\n",
    "            \n",
    "WordNet.download()\n",
    "OPTED.download()\n",
    "Webster.download()\n",
    "\n",
    "OANC.download()\n",
    "WarAndPeace.download()\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
